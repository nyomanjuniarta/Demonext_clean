{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "from utils import printProgressBar\n",
    "\n",
    "# column number Demonette\n",
    "graph_1 = 3\n",
    "graph_2 = 6\n",
    "cat_1 = 8\n",
    "cat_2 = 10\n",
    "cstr_1 = 14\n",
    "cstr_2 = 17\n",
    "complexite = 19\n",
    "orientation = 21\n",
    "fichier_origine = 43\n",
    "\n",
    "# column number Glawinette\n",
    "lemma1 = 0\n",
    "lemma2 = 1\n",
    "cat1 = 2\n",
    "cat2 = 3\n",
    "origine_morpho = 4\n",
    "origine_def = 5\n",
    "BAP1 = 6\n",
    "BAP2 = 7\n",
    "BAPsize = 8\n",
    "FAP1 = 9\n",
    "FAP2 = 10\n",
    "FAPsize = 11\n",
    "radical = 12\n",
    "FAPtype = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749466cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_needed = ['DG-families', 'DG-graph', 'raw_csv_files']\n",
    "for f in folders_needed:\n",
    "    if not os.path.exists(f):\n",
    "        os.makedirs(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6997adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAPconverter(input_fap):\n",
    "    return input_fap.replace('(.+)', 'X').replace('$', '').replace('^', '')\n",
    "\n",
    "header = ''\n",
    "glawi_dict = dict()\n",
    "glawi_const_set = set()\n",
    "with codecs.open('glawinette-series.csv', 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if line_num >= 1:\n",
    "            elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "            construction12 = FAPconverter(elements[FAP1]) + '-' + FAPconverter(elements[FAP2])\n",
    "            construction21 = FAPconverter(elements[FAP2]) + '-' + FAPconverter(elements[FAP1])\n",
    "            glawi_const_set.add(construction12)\n",
    "            glawi_const_set.add(construction21)\n",
    "            glawi_dict[(elements[lemma1], elements[lemma2])] = construction12\n",
    "            glawi_dict[(elements[lemma2], elements[lemma1])] = construction21\n",
    "print(len(glawi_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a205bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glawi_const_set = list(glawi_const_set)\n",
    "glawi_const_set.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'raw_csv_files'\n",
    "input_files = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n",
    "if '.gitignore' in input_files:\n",
    "    input_files.remove('.gitignore')\n",
    "input_files.sort()\n",
    "\n",
    "input_file_code = dict()\n",
    "input_file_code['converts'] = 'C'\n",
    "input_file_code['demonette1'] = 'D'\n",
    "input_file_code['mordan'] = 'M'\n",
    "\n",
    "input_file_code['denomCONVX'] = 'Na'\n",
    "input_file_code['denomPREFX'] = 'Nb'\n",
    "input_file_code['denomXaire'] = 'Nc'\n",
    "input_file_code['denomXal'] = 'Nd'\n",
    "input_file_code['denomXique'] = 'Ne'\n",
    "input_file_code['denomXSUF1'] = 'Nf'\n",
    "input_file_code['denomXSUF2'] = 'Ng'\n",
    "input_file_code['denomXSUF3'] = 'Nh'\n",
    "input_file_code['denomXSUF4'] = 'Ni'\n",
    "input_file_code['denomXSUF5'] = 'Nj'\n",
    "input_file_code['denomXSUF6'] = 'Nk'\n",
    "\n",
    "input_file_code['dimocXaie'] = 'Ma'\n",
    "input_file_code['dimocXat'] = 'Mb'\n",
    "input_file_code['dimocXet'] = 'Mc'\n",
    "input_file_code['dimocXier'] = 'Md'\n",
    "input_file_code['dimocXasmeXaste'] = 'Me'\n",
    "input_file_code['dimocXite'] = 'Mf'\n",
    "input_file_code['dimocXien'] = 'Mg'\n",
    "input_file_code['dimocXisme'] = 'Mh'\n",
    "input_file_code['dimocXiste'] = 'Mi'\n",
    "\n",
    "input_file_code['derifantiX'] = 'Ra'\n",
    "input_file_code['derifde1X'] = 'Rb'\n",
    "input_file_code['derifenX'] = 'Rc'\n",
    "input_file_code['derifinX'] = 'Rd'\n",
    "input_file_code['derifQUANTX'] = 'Re'\n",
    "input_file_code['derifreX'] = 'Rf'\n",
    "input_file_code['deriftriX'] = 'Rg'\n",
    "input_file_code['derifXable'] = 'Rh'\n",
    "input_file_code['derifXiser'] = 'Ri'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc60c8",
   "metadata": {},
   "source": [
    "# 1. Identify families of lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ac808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative(K):\n",
    "    # a representative of a family: the root (no direct relation going in), or the node with the largest outdegree\n",
    "    in_degree_dict = dict()  # only counting 'des2as' and 'as2des'\n",
    "    for v in list(K.nodes):\n",
    "        in_degree_dict[v] = 0\n",
    "    for e in list(K.edges.data()):\n",
    "        if not ('NA' in e[2]['label'] or 'indirect' in e[2]['label']):\n",
    "            in_degree_dict[e[1]] += 1\n",
    "    roots = list()\n",
    "    for k in in_degree_dict:\n",
    "        if in_degree_dict[k] == 0:\n",
    "            roots.append(k)\n",
    "    if len(roots) == 1:\n",
    "        return roots[0].split('_')[0]\n",
    "    elif len(roots) == 0:\n",
    "        max_out_degree = 0\n",
    "        selected_node = ''\n",
    "        for n in list(K.nodes):\n",
    "            if K.out_degree(n) > max_out_degree:\n",
    "                max_out_degree = K.out_degree(n)\n",
    "                selected_node = n\n",
    "        return selected_node.split('_')[0]\n",
    "    elif len(roots) > 1:\n",
    "        max_out_degree = 0\n",
    "        selected_root = roots[0]\n",
    "        for r in roots:\n",
    "            if K.out_degree(r) > max_out_degree:\n",
    "                max_out_degree = K.out_degree(r)\n",
    "                selected_root = r\n",
    "        return selected_root.split('_')[0]\n",
    "    \n",
    "def category_shortening(cat):\n",
    "    if cat != 'Num' and cat[0] == 'N':\n",
    "        if cat[1] == 'p':  # nom propre\n",
    "            return 'Np'\n",
    "        return 'N'  # nom\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac091e",
   "metadata": {},
   "source": [
    "Create arc between two lexemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ''\n",
    "G = nx.DiGraph()\n",
    "number_of_pairs = 0\n",
    "number_of_unique_pairs = 0\n",
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num == 0:\n",
    "                header = line.replace('\\n','')\n",
    "            elif line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if G.has_edge(v1, v2) or G.has_edge(v2, v1):\n",
    "                    continue\n",
    "                G.add_node(v1, label=category_shortening(elements[cat_1]))\n",
    "                G.add_node(v2, label=category_shortening(elements[cat_2]))\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        G.add_edge(v1, v2, label=elements[cstr_1] + '-' + elements[cstr_2]\\\n",
    "                                   + '$' + glawi_dict.get((elements[graph_1], elements[graph_2])))\n",
    "                    else:\n",
    "                        G.add_edge(v1, v2, label=elements[cstr_1] + '-' + elements[cstr_2])\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    if (elements[graph_2], elements[graph_1]) in glawi_dict.keys():\n",
    "                        G.add_edge(v2, v1, label=elements[cstr_2] + '-' + elements[cstr_1]\\\n",
    "                                   + '$' + glawi_dict.get((elements[graph_2], elements[graph_1])))\n",
    "                    else:\n",
    "                        G.add_edge(v2, v1, label=elements[cstr_2] + '-' + elements[cstr_1])\n",
    "                else:\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        G.add_edge(v1, v2, label=elements[cstr_1] + '-' + elements[cstr_2] + '_' + elements[orientation]\\\n",
    "                                   + '$' + glawi_dict.get((elements[graph_1], elements[graph_2])) +  '_' + elements[orientation])\n",
    "                        G.add_edge(v2, v1, label=elements[cstr_2] + '-' + elements[cstr_1] + '_' + elements[orientation]\\\n",
    "                                   + '$' + glawi_dict.get((elements[graph_2], elements[graph_1])) +  '_' + elements[orientation])\n",
    "                    else:\n",
    "                        G.add_edge(v1, v2, label=elements[cstr_1] + '-' + elements[cstr_2] + '_' + elements[orientation])\n",
    "                        G.add_edge(v2, v1, label=elements[cstr_2] + '-' + elements[cstr_1] + '_' + elements[orientation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a031fc",
   "metadata": {},
   "source": [
    "A connected component is regarded as a family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195104c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_comps = list(nx.weakly_connected_components(G))\n",
    "number_of_families = len(conn_comps)\n",
    "print(number_of_families, 'families')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765bf47",
   "metadata": {},
   "source": [
    "Comparing every pair of families to detect isomorphy groups\n",
    "\n",
    "O(n^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked = list()\n",
    "H = nx.Graph() # graph of graphs\n",
    "for fam1 in range(0, number_of_families):\n",
    "    printProgressBar(fam1 + 1, number_of_families, prefix = 'Progress:', suffix = 'complete', length = 50, decimals = 2)\n",
    "    if fam1 in checked:\n",
    "        continue\n",
    "    H.add_node(fam1)\n",
    "    for fam2 in range(fam1 + 1, number_of_families):\n",
    "        if fam2 in checked:\n",
    "            continue\n",
    "        G1 = nx.subgraph(G, conn_comps[fam1])\n",
    "        G2 = nx.subgraph(G, conn_comps[fam2])\n",
    "        if nx.is_isomorphic(G1, G2, node_match=lambda v1,v2: v1['label'] == v2['label'],\\\n",
    "                            edge_match=lambda e1,e2: e1['label'] == e2['label']):\n",
    "            checked.append(fam2)\n",
    "            H.add_edge(fam1, fam2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ca67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_conn_comps = [c for c in sorted(nx.connected_components(H), key=len, reverse=False)]\n",
    "print(len(H_conn_comps), 'isomorphy groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f9777",
   "metadata": {},
   "source": [
    "Generate csv file for each family to folder \"DG-families\", and\n",
    "\n",
    "Generate \"DG_summary_of_families.txt\" that records the list of lexemes for each family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1057f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'DG-families'\n",
    "lexeme_dict = dict()\n",
    "f_summary = codecs.open('DG_summary_of_families.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('family_id\\tnumber_of_lexemes\\tlexemes\\n')\n",
    "for fam_fam_id, fam_fam in enumerate(H_conn_comps):\n",
    "    for fam_id, fam in enumerate(fam_fam):\n",
    "        representative = find_representative(nx.subgraph(G, conn_comps[fam]))\n",
    "        if len(fam_fam) == 1:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0')\n",
    "        else:\n",
    "            family_title = 'F' + str(fam_fam_id).rjust(5, '0') + '-' + str(fam_id).rjust(len(str(len(fam_fam)-1)), '0')\n",
    "        f_summary.write(family_title + '\\t'\\\n",
    "                       + str(len(conn_comps[fam])) + '\\t' + str(conn_comps[fam]) + '\\n')\n",
    "        for lexeme in conn_comps[fam]:\n",
    "            filename = family_title + ' ' + representative + '.txt'\n",
    "            lexeme_dict[lexeme] = filename\n",
    "            f_out = codecs.open(join(output_folder, filename), 'w+', encoding='utf-8')\n",
    "            f_out.write(header + '\\tfichier_origine' + '\\n\\n')\n",
    "            f_out.close()\n",
    "f_summary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in input_files:\n",
    "    with codecs.open(join(input_dir, input_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num < 2:\n",
    "                continue\n",
    "            elements = line.replace(' ','').split('\\t')\n",
    "            lexeme1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "            if elements[complexite] not in ['simple', 'complexe', 'motiv-form', 'motiv-sem', 'accidentel']:\n",
    "                print('warning ', input_file)\n",
    "            output_filename = lexeme_dict[lexeme1]\n",
    "            f_out = codecs.open(join(output_folder, output_filename), 'a+', encoding='utf-8')\n",
    "            f_out.write(line.strip('\\n') + '\\t' + input_file_code.get(input_file.split('-')[0], '?') + '\\n')\n",
    "            f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5115434",
   "metadata": {},
   "source": [
    "# 2. Generate graphs (.dot files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4748deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_shortening(cat):\n",
    "    if cat != 'Num' and cat[0] == 'N':\n",
    "        if cat[1] == 'p':  # nom propre\n",
    "            return 'Np'\n",
    "        return 'N'  # nom\n",
    "    return cat\n",
    "\n",
    "def edge_writer(L):\n",
    "    ret_str = ''\n",
    "    edges = L.edges(data=True)\n",
    "    for e in edges:\n",
    "        cat0 = category_shortening(e[0].split('_')[1])\n",
    "        cat1 = category_shortening(e[1].split('_')[1])\n",
    "        label_demon = e[2]['label'].split('\\n')[0]\n",
    "        if e[2]['style'] == 'dotted': \n",
    "            ret_str += cat0 + ' -- ' + label_demon.split(': ')[1] + ' -- ' + cat1 + '; '\n",
    "        elif e[2]['style'] == 'dashed':\n",
    "            ret_str += cat0 + ' -? ' + label_demon.split(': ')[1] + ' -? ' + cat1 + '; '\n",
    "        else:\n",
    "            ret_str += cat0 + ' -> ' + label_demon.split(': ')[1] + ' -> ' + cat1 + '; '\n",
    "        if '\\n' in e[2]['label']:\n",
    "            label_glawi = e[2]['label'].split('\\n')[1]\n",
    "            if e[2]['style'] == 'dotted': \n",
    "                ret_str += cat0 + ' -- ' + label_glawi.split(': ')[1] + ' -- ' + cat1 + '; '\n",
    "            elif e[2]['style'] == 'dashed':\n",
    "                ret_str += cat0 + ' -? ' + label_glawi.split(': ')[1] + ' -? ' + cat1 + '; '\n",
    "            else:\n",
    "                ret_str += cat0 + ' -> ' + label_glawi.split(': ')[1] + ' -> ' + cat1 + '; '\n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a6507",
   "metadata": {},
   "source": [
    "Generate .dot file for each family, and \"DG_summary_of_groups.txt\" that records the list of edges for each isomorphy group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_summary = codecs.open('DG_summary_of_groups.txt', 'w+', encoding='utf-8')\n",
    "f_summary.write('group id\\tnumber of lexemes\\tnumber of edges\\tnumber of families\\tedges\\tfamilies\\n')\n",
    "number_of_edges = []\n",
    "number_of_families = []\n",
    "words = ''\n",
    "group_prec = ''\n",
    "family_count = 0\n",
    "L = nx.DiGraph()\n",
    "family_dir = 'DG-families'\n",
    "family_files = [f for f in listdir(family_dir) if isfile(join(family_dir, f))]\n",
    "if '.gitignore' in family_files:\n",
    "    family_files.remove('.gitignore')\n",
    "for family_file in family_files:\n",
    "    group_id = family_file.split(' ')[0].split('-')[0]\n",
    "    if group_id != group_prec and group_prec != '':\n",
    "        f_summary.write(group_prec + '\\t' + str(len(L)) + '\\t' + str(L.size()) + '\\t' + str(family_count) + '\\t')\n",
    "        f_summary.write(edge_writer(L)[:-2])\n",
    "        f_summary.write('\\t' + words[:-2] + '\\n')\n",
    "        family_count = 0\n",
    "        words = ''\n",
    "    family_count += 1\n",
    "    group_prec = group_id\n",
    "    L = nx.DiGraph()\n",
    "    with codecs.open(join(family_dir, family_file), 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f):\n",
    "            if line_num >= 2:\n",
    "                elements = line.replace('\\n','').replace(' ','').split('\\t')\n",
    "                v1 = elements[graph_1] + '_' + elements[cat_1]\n",
    "                v2 = elements[graph_2] + '_' + elements[cat_2]\n",
    "                if L.has_edge(v1, v2) or L.has_edge(v2, v1):\n",
    "                    continue\n",
    "                L.add_node(v1, label=elements[graph_1] + '\\n' + category_shortening(elements[cat_1]))\n",
    "                L.add_node(v2, label=elements[graph_2] + '\\n' + category_shortening(elements[cat_2]))\n",
    "                if elements[orientation] == 'as2de' or elements[orientation] == 'as2des':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        L.add_edge(v1, v2, label=edge_type + '\\nG: ' + glawi_dict.get((elements[graph_1], elements[graph_2])), style='')\n",
    "                    else:\n",
    "                        L.add_edge(v1, v2, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'de2as' or elements[orientation] == 'des2as':\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_2] + '-' + elements[cstr_1]\n",
    "                    if (elements[graph_2], elements[graph_1]) in glawi_dict.keys():\n",
    "                        L.add_edge(v2, v1, label=edge_type + '\\nG: ' + glawi_dict.get((elements[graph_2], elements[graph_1])), style='')\n",
    "                    else:\n",
    "                        L.add_edge(v2, v1, label=edge_type, style='')\n",
    "                elif elements[orientation] == 'indirect':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        L.add_edge(v1, v2, dir='none', style='dotted', \\\n",
    "                                   label=edge_type + '\\nG: ' + glawi_dict.get((elements[graph_1], elements[graph_2])))\n",
    "                    else:\n",
    "                        L.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dotted', label=edge_type)\n",
    "                elif elements[orientation] == 'NA':\n",
    "                    sorted_lex = sorted([v1, v2])\n",
    "                    edge_type = elements[fichier_origine] + ': ' + elements[cstr_1] + '-' + elements[cstr_2]\n",
    "                    if (elements[graph_1], elements[graph_2]) in glawi_dict.keys():\n",
    "                        L.add_edge(v1, v2, dir='none', style='dashed',\\\n",
    "                                   label=edge_type + '\\nG: ' + glawi_dict.get((elements[graph_1], elements[graph_2])))\n",
    "                    else:\n",
    "                        L.add_edge(sorted_lex[0], sorted_lex[1], dir='none', style='dashed', label=edge_type)\n",
    "    words += str(list(L.nodes())) + '; '\n",
    "    write_dot(L, join('DG-graph', family_file.replace('.txt','.dot')))\n",
    "    print(family_file.split(' ')[0], end='\\r')\n",
    "f_summary.write(group_prec + '\\t' + str(len(L)) + '\\t' + str(L.size()) + '\\t' + str(family_count) + '\\t')\n",
    "f_summary.write(edge_writer(L)[:-2])\n",
    "f_summary.write('\\t' + words[:-2] + '\\n')  \n",
    "f_summary.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
